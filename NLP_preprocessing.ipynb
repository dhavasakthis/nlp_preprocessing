{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In Natural Language Processing (NLP), preprocessing is a crucial step that involves transforming raw text data into a format that can be efficiently and effectively used by machine learning models. Here are the key steps involved in NLP preprocessing:\n",
        "\n",
        "1. Text Cleaning\n",
        "Lowercasing: Convert all text to lowercase to ensure uniformity.\n",
        "Removing Punctuation: Remove or handle punctuation marks.\n",
        "Removing Special Characters: Remove characters like #, @, &, etc.\n",
        "Removing Numbers: Depending on the context, numbers might be removed.\n",
        "2. Tokenization\n",
        "Word Tokenization: Split the text into individual words.\n",
        "Sentence Tokenization: Split the text into sentences.\n",
        "Subword Tokenization: Break down words into subwords, especially useful for handling out-of-vocabulary words.\n",
        "3. Stop Word Removal\n",
        "Stop Words: Remove common words like \"and,\" \"the,\" \"is,\" etc., that do not contribute significantly to the meaning of the text.\n",
        "4. Stemming and Lemmatization\n",
        "Stemming: Reduce words to their root form (e.g., \"running\" to \"run\").\n",
        "Lemmatization: Reduce words to their base or dictionary form (e.g., \"better\" to \"good\").\n"
      ],
      "metadata": {
        "id": "VeFUxTq3DCJn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6vC_Wpn-VKD",
        "outputId": "fdf6072d-7c61-40e0-ea15-e6ae74ac58ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XImfTZvx-ZqQ",
        "outputId": "b6fb6bb2-2add-4723-c33a-44ae2d76e056"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a simple example: we're going to preprocess this text, removing stopwords and punctuation.\""
      ],
      "metadata": {
        "id": "03ssijK_-p4x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "-hi1YNND-sIp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMNksQwk-wC4",
        "outputId": "9faafc54-d689-4004-db35-96d24f1d68e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'simple',\n",
              " 'example',\n",
              " ':',\n",
              " 'we',\n",
              " \"'re\",\n",
              " 'going',\n",
              " 'to',\n",
              " 'preprocess',\n",
              " 'this',\n",
              " 'text',\n",
              " ',',\n",
              " 'removing',\n",
              " 'stopwords',\n",
              " 'and',\n",
              " 'punctuation',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lower case & removal of puntuation\n",
        "cw = [word.lower() for word in words if word.isalpha()]"
      ],
      "metadata": {
        "id": "Fl_yzFQy_HdV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "809f5083_ZZO",
        "outputId": "438edbd6-6cae-4dfd-d27d-848342ae0075"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'simple',\n",
              " 'example',\n",
              " 'we',\n",
              " 'going',\n",
              " 'to',\n",
              " 'preprocess',\n",
              " 'this',\n",
              " 'text',\n",
              " 'removing',\n",
              " 'stopwords',\n",
              " 'and',\n",
              " 'punctuation']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in cw if word not in stop_word]"
      ],
      "metadata": {
        "id": "kySv-slJ_c9K"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "\n",
        "print(\"\\nTokenized Text:\")\n",
        "print(words)\n",
        "\n",
        "print(\"\\nCleaned and Stop Words Removed:\")\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQtAyboO_5D7",
        "outputId": "c82e3e8a-22ce-4f98-86b2-9611c365b75b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "This is a simple example: we're going to preprocess this text, removing stopwords and punctuation.\n",
            "\n",
            "Tokenized Text:\n",
            "['This', 'is', 'a', 'simple', 'example', ':', 'we', \"'re\", 'going', 'to', 'preprocess', 'this', 'text', ',', 'removing', 'stopwords', 'and', 'punctuation', '.']\n",
            "\n",
            "Cleaned and Stop Words Removed:\n",
            "['simple', 'example', 'going', 'preprocess', 'text', 'removing', 'stopwords', 'punctuation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Srg-q0WIBbCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}